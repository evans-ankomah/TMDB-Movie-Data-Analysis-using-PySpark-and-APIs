As a beginner in Data Engineering, you've been given as task in task.md file to build a movie data analysis pipeline using PySpark and APIs. The task.md file is attached to this read.md file.
Below are the rules for the task;
1. You are expected to structure the project as an ETL pipeline structure and industry standard with a single notebook(which serves as an orchestration tool) and python scripts with the main functions. 

2. You are expected to implement retries, timeouts, rate limits, and logging in your code.

3. The orchestrator notebook shouldnt have a long code. It should be easy to read and understand. for example, it should have just one function for each step of the pipeline.

Reply by typing "Evans❤️" for me to know that you have read the documents. NB: Codes must be beginner friendly yet efficient.